{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Keras\n",
    "\n",
    "Welcome to your (possibly) first Machine Learning tutorial.\n",
    "\n",
    "We will be using the Logistic Regression (a one-layer Neural Network) to recognise hand written digits in images.\n",
    "\n",
    "The MNIST database of handwritten digits has been a benchmark in Computer Vision for many years. Although it is considered \"solved\" by many today, new algorithms are still tested on it first, and it still serves as a good learning tool.\n",
    "\n",
    "More information on MNIST including results from prominent researchers in the field who developed a variety of models to improve classification accuracy:\n",
    "\n",
    "> http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Quick intro to Jupyter controls:\n",
    "\n",
    "> Select a cell and Ctrl+Enter - this will execute the selected cell. For more shortcuts, go to Help -> Keyboard Shortcuts\n",
    "\n",
    "> Go through each cell and execute it to see the result\n",
    "\n",
    "Useful links:\n",
    "\n",
    "> https://en.wikipedia.org/wiki/Logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import useful code packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cdedf6717b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import Keras model layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import Keras model layers\n",
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and load the MNIST dataset - the file will be downloaded only once and saved in the Anaconda environment\n",
    "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Print shapes and bounds\n",
    "print('Train set:')\n",
    "print('Sizes:', X_train_raw.shape, y_train_raw.shape)\n",
    "\n",
    "print('Test set:')\n",
    "print('Sizes:', X_test_raw.shape, y_test_raw.shape)\n",
    "\n",
    "print('Image values (min to max):', np.min(X_train_raw), 'to', np.max(X_train_raw))\n",
    "print('Label values (min to max):', np.min(y_train_raw), 'to', np.max(y_train_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation\n",
    "\n",
    "The data was loaded, but the pixel values are not suitable for learning with a Neural Network. Also, labels have to be in one-hot format.\n",
    "\n",
    "* Divide raw image data in both training and test set by the maximum value\n",
    "\n",
    "* Flatten the images into 1D vectors. Use NumPy's reshape function:\n",
    "    https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\n",
    "\n",
    "* Convert the raw numeric labels (0..9) to one-hot vectors - Keras has a builtin function to do just that:\n",
    "    https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise raw image data by dividing by the maximum value\n",
    "X_train = X_train_raw / 255 # normalise X_train\n",
    "X_test = X_test_raw / 255 # normalise X_test\n",
    "\n",
    "# flatten normalised data into 1D vectors\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# convert raw labels to one-hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train_raw, num_classes=10) # convert y_train\n",
    "y_test = keras.utils.to_categorical(y_test_raw, num_classes=10) # convert y_test\n",
    "\n",
    "# shuffle training samples (same permutation for X and Y so that labels still correspond)\n",
    "np.random.seed(42) # fix random seed so that everyone has the same dataset permutation\n",
    "permutation = np.random.permutation(X_train.shape[0])\n",
    "X_train = X_train[permutation]\n",
    "y_train = y_train[permutation]\n",
    "\n",
    "# Print shapes and bounds\n",
    "print('### Train set:')\n",
    "print('Sizes:', X_train.shape, y_train.shape)\n",
    "print('Image values (min to max):', np.min(X_train), 'to', np.max(X_train))\n",
    "print('Label values (min to max):', np.min(y_train), 'to', np.max(y_train))\n",
    "print('Total samples per class:', np.sum(y_train, axis=0))\n",
    "\n",
    "print('### Test set:')\n",
    "print('Sizes:', X_test.shape, y_test.shape)\n",
    "print('Image values (min to max):', np.min(X_test), 'to', np.max(X_test))\n",
    "print('Label values (min to max):', np.min(y_test), 'to', np.max(y_test))\n",
    "print('Total samples per class:', np.sum(y_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "\\### Train set:<br>\n",
    "Sizes: (60000, 784) (60000, 10)<br>\n",
    "Image values (min to max): 0.0 to 1.0<br>\n",
    "Label values (min to max): 0.0 to 1.0<br>\n",
    "Total samples per class: [5923. 6742. 5958. 6131. 5842. 5421. 5918. 6265. 5851. 5949.]<br>\n",
    "\\### Test set:<br>\n",
    "Sizes: (10000, 784) (10000, 10)<br>\n",
    "Image values (min to max): 0.0 to 1.0<br>\n",
    "Label values (min to max): 0.0 to 1.0<br>\n",
    "Total samples per class: [ 980. 1135. 1032. 1010.  982.  892.  958. 1028.  974. 1009.]<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some samples\n",
    "\n",
    "Change the index to see other samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a function to display a sample\n",
    "def display_digit(index, xs, ys, title):\n",
    "    label = np.argmax(ys[index]) # argmax used to convert from one-hot back to numeric label\n",
    "    image = xs[index].reshape([28,28]) # make sure that the data is in 2D shape\n",
    "    plt.title(title+': Index: %d  Label: %d' % (index, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "\n",
    "display_digit(index=0, xs=X_train, ys=y_train, title='Train sample') # display the first training example\n",
    "display_digit(index=0, xs=X_test,  ys=y_test,  title='Test sample')  # display the first test example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right, the classes seem very easy to separate ! Let's prepare to train our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "We will build a neural network with a single layer:\n",
    "\n",
    "* Use Kera's Dense to create a Fully Connected layer, use 'softmax' activation\n",
    "\n",
    "![](./images/lr_diag.png \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input and output sizes\n",
    "input_dim = X_train.shape[1] # 784\n",
    "output_dim = y_train.shape[1] # 10\n",
    "\n",
    "# Create Sequential model - this allows you to add layers one after the other to build your model\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim, input_dim=input_dim, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "optim = keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "> **Note**: Be sure to rerun the previous cell before you train, otherwise previous weights will be kept - i.e. you would just train your model further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "batch_size = 32\n",
    "nb_epoch = 15\n",
    "\n",
    "# train the model and save training history\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size, \n",
    "          epochs=nb_epoch, \n",
    "          verbose=1, \n",
    "          validation_split=1./6., # set 10K samples (out of 60K) aside for validation\n",
    ")\n",
    "\n",
    "# save model weights to file\n",
    "model.save_weights('mnist_logistic_regression.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss and accuracy\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['training', 'validation'], loc='upper right')\n",
    "ax1.yaxis.grid()\n",
    "\n",
    "ax2.plot(history.history['accuracy'])\n",
    "ax2.plot(history.history['val_accuracy'])\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['training', 'validation'], loc='upper left')\n",
    "ax2.yaxis.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights from file\n",
    "model.load_weights('mnist_logistic_regression.h5')\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have obtained a value of around 0.91-0.92 (which means 91%-92% test accuracy). Congratulations !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the following\n",
    "\n",
    "1) Change the learning rate (e.g. 0.0001, 0.001, 0.01, 0.1) and observe the training curves\n",
    "\n",
    "2) Add Momentum to the SGD optimizer (https://keras.io/optimizers/) and observe the accuracy\n",
    "\n",
    "3) Change the batch size (e.g. 8, 16, 32, 64, 128, 256) and see what happens (time per epoch, accuracy, etc)\n",
    "\n",
    "4) Try a different optimizer altogether (e.g. Adam) (https://keras.io/optimizers/)\n",
    "\n",
    "5) Try adding shuffling during training (https://keras.io/models/sequential/)\n",
    "\n",
    "6) Share your best results !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
