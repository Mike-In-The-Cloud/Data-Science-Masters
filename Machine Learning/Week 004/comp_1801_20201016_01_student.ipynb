{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjT_s9uVn-NS"
   },
   "source": [
    "# Automatic differentiation and Gradient Descent\n",
    "- COMP 1801 IT lab: 09 Oct 2020\n",
    "$\\newcommand{\\Vec}[1]{\\boldsymbol{#1}}$\n",
    "$\\newcommand{\\Mat}[1]{\\boldsymbol{#1}}$\n",
    "## Aim\n",
    "- Learn the ability vectorisation notation and the ability to convert equations to a modern language code such as Numpy\n",
    "- Learn how effective vectorisation is.\n",
    "- Learn how gradient descent works \n",
    "## Note: to execute a cell, press SHIFT + ENTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na1S4jagpCxS"
   },
   "source": [
    "## Import libraries\n",
    "- Numpy: for vectors, matrices\n",
    "- Tensorflow: for automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-RdAt6FxjGqL"
   },
   "outputs": [],
   "source": [
    "import numpy as np # import numpy and set \"np\" as the alias of the numpy\n",
    "import tensorflow as tf # import tensorflow and set \"tf\" as the alias of the tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfX6E4xJp4Pu"
   },
   "source": [
    "## Variable and constant\n",
    "### Defining a \"variable\" (a variable with respect to which we will calculate the derivative.)\n",
    "- $\\texttt{tf.Variable(value, dtype=np.float32)}$\n",
    "  - $\\texttt{value}$ can be a python list, numpy array, or tensorflow Tensor, and will be regarded as the initial value.\n",
    "\n",
    "### Defining a \"constant\" (a variable for which we do not need to calculate the derivative)\n",
    "- $\\texttt{tf.constant(value, dtype=np.float32)}$\n",
    "  - $\\texttt{value}$ is the value of the \"constant Tensor\"\n",
    "  - Strictly speaking, the \"Tensor\" defined by this is immutable, so not \"constant.\"\n",
    "\n",
    "### Mathematical functions\n",
    "- Operators are similar to those in Numpy\n",
    "  - $\\texttt{+, -, *, /}$: elementwise addition, subtraction, multiplication, division\n",
    "  - $\\texttt{@}$: matrix product\n",
    "- Most mathmatical function can be given by replacing np of a Numpy function by tf.math\n",
    "  - $\\texttt{np.sin(x), np.cos(x), np.exp(x)} \\to \\texttt{tf.math.sin(x), tf.math.cos(x), tf.math.exp(x)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KUhg85qqq3Q"
   },
   "source": [
    "## Automatic differentiation\n",
    "- Define the Variables (e.g. $\\texttt{th}$) and constants\n",
    "- Define return value (e.g. $\\texttt{j}$) in $\\texttt{tf.GradientTape() as tape:} block$\n",
    "- Get the gradient by $\\texttt{tape.gradient()}$ (e.g. $\\texttt{tape.gradient(j, th)}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D60hTD2ZjT2t"
   },
   "source": [
    "# Scalar example 1\n",
    "## Problem\n",
    "Let $a = 5$. Define $J$ by $J(\\theta) := a \\theta^3$.\n",
    "- $\\frac{d}{d\\theta} J(-2)=?$\n",
    "\n",
    "## Solution\n",
    "- $\\frac{d}{d\\theta} J(\\theta)=3 a \\theta^2$\n",
    "- $\\frac{d}{d\\theta} J(-2)= 3 \\cdot 5 \\cdot (-2)^2 = 60$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "p2eo5lcHjsf-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j = -40.0\n",
      "dj/dth = 60.0\n"
     ]
    }
   ],
   "source": [
    "th = tf.Variable(-2, dtype=np.float32)\n",
    "a = tf.constant(5, dtype=np.float32)\n",
    "def j_func(th):\n",
    "  j = a * (th ** 3)\n",
    "  return j\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  j = j_func(th)\n",
    "\n",
    "print('j =', j.numpy())\n",
    "\n",
    "dj_dth = tape.gradient(j, th)\n",
    "print('dj/dth =', dj_dth.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVN-xvgfmYHA"
   },
   "source": [
    "# Scalar example 2\n",
    "## Problem\n",
    "Let $a = 3$. Define $J$ by $J(\\theta) := \\exp (\\theta^2 + a)$.\n",
    "- $\\frac{d}{d\\theta} J(1)=?$\n",
    "\n",
    "## Solution\n",
    "- $\\frac{d}{d\\theta} J(\\theta)=2 \\theta \\exp (\\theta^2 + a)$\n",
    "- $\\frac{d}{d\\theta} J(1)= 2 \\cdot 1 \\exp (1^2 + 3) = 2 \\times \\exp(4) \\approx 109.19$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OG7-llzrbac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j = 54.59815\n",
      "dj/dth = 109.1963\n"
     ]
    }
   ],
   "source": [
    "th = tf.Variable(1, dtype=np.float32)\n",
    "a = tf.constant(3, dtype=np.float32)\n",
    "def j_func(th):\n",
    "  j = tf.math.exp(th ** 2 + a)\n",
    "  return j\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  j = j_func(th)\n",
    "\n",
    "print('j =', j.numpy())\n",
    "\n",
    "dj_dth = tape.gradient(j, th)\n",
    "print('dj/dth =', dj_dth.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTlTc6enl0qz"
   },
   "source": [
    "# Problem: sigmoid function (YOU NEED TO MODIFY CODES)\n",
    "\n",
    "## Problem \n",
    "Let $a = 1$. Define $J$ by $$J(\\theta) := \\frac{1}{1 + \\exp (- a \\theta)}$$.\n",
    "- $\\frac{d}{d\\theta} J(0)=?$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kVo9G_xsmqVd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j = 0.5\n",
      "dj/dth = 0.25\n"
     ]
    }
   ],
   "source": [
    "th = tf.Variable(0, dtype=np.float32)\n",
    "a = tf.constant(1, dtype=np.float32)\n",
    "def j_func(th):\n",
    "  j = 0.0 * th\n",
    "  # modify code: correct the definition of j\n",
    "  j = 1 / (1+tf.math.exp(-a*th))\n",
    "  # modify code: correct the definition of j\n",
    "  return j\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  j = j_func(th)\n",
    "\n",
    "print('j =', j.numpy())\n",
    "\n",
    "dj_dth = tape.gradient(j, th)\n",
    "print('dj/dth =', dj_dth.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk3TSyKvcHp_"
   },
   "source": [
    "# Vector/Matrix example 1\n",
    "## Problem\n",
    "Let $\\Vec{c} = \\begin{bmatrix}2 \\\\ 3\\end{bmatrix}$. Define $J$ by \n",
    "$$J(\\Vec{\\theta}) := \\sum_{i=0,1}(\\theta_{i} - c_{i})^2 = (\\Vec{\\theta} - \\Vec{c})^\\top (\\Vec{\\theta} - \\Vec{c}).$$\n",
    "- $\\frac{\\partial}{\\partial \\Vec{\\theta}} J \\left(\\begin{bmatrix}5 \\\\ 4\\end{bmatrix}\\right) = \\begin{bmatrix}\\frac{\\partial}{\\partial \\theta_{0}} \\\\ \\frac{\\partial}{\\partial \\theta_{i}}\\end{bmatrix} \\left(\\begin{bmatrix}5 \\\\ 4\\end{bmatrix}\\right) = ?$\n",
    "\n",
    "## Solution\n",
    "- $\\frac{\\partial}{\\partial \\Vec{\\theta}} J (\\Vec{\\theta}) = 2 (\\Vec{\\theta} - \\Vec{c})$\n",
    "- $\\frac{\\partial}{\\partial \\Vec{\\theta}} J \\left(\\begin{bmatrix}5 \\\\ 4\\end{bmatrix}\\right) = 2 \\left(\\begin{bmatrix}5 \\\\ 4\\end{bmatrix} - \\begin{bmatrix}2 \\\\ 3\\end{bmatrix}\\right) = \\begin{bmatrix}6 \\\\ 2\\end{bmatrix}.$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "82I1RI3ifZhy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j = [[10.]]\n",
      "dj/dth = [[6.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "th_by_list = \\\n",
    "[\n",
    "  [5],\n",
    "  [4],\n",
    "]\n",
    "c_by_list = \\\n",
    "[\n",
    "  [2],\n",
    "  [3],\n",
    "]\n",
    "\n",
    "th = tf.Variable(th_by_list, dtype=np.float32)\n",
    "c = tf.constant(c_by_list, dtype=np.float32)\n",
    "def j_func(th):\n",
    "  j = tf.transpose(th - c) @ (th - c) # (th - c).T does not work in Tensorflow\n",
    "  return j\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  j = j_func(th)\n",
    "\n",
    "print('j =', j.numpy())\n",
    "\n",
    "dj_dth = tape.gradient(j, th)\n",
    "print('dj/dth =', dj_dth.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ew4IJROBiH2h"
   },
   "source": [
    "# Vector/Matrix example 2\n",
    "## Problem\n",
    "Let $\\Vec{y} = \\begin{bmatrix}1 \\\\ 1 \\\\ 0\\end{bmatrix}$. Define $J$ by \n",
    "$$J(\\Vec{\\theta}) := \\sum_{i=0,1} \\left[- y_{i} \\log (\\theta_{i}) - (1 - y_{i}) \\log (1 - \\theta_{i}) \\right] = \\Vec{1}^\\top \\left[- \\Vec{y} \\otimes \\log (\\Vec{\\theta}) - (\\Vec{1} - \\Vec{y}) \\otimes \\log (\\Vec{1} - \\Vec{\\theta}) \\right].$$\n",
    "- $\\frac{\\partial}{\\partial \\Vec{\\theta}} J \\left(\\begin{bmatrix}0.8 \\\\ 0.7 \\\\ 0.3\\end{bmatrix}\\right) = ?$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7RMcv4Y2kUD8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j = [[0.93649346]]\n",
      "dj/dth = [[-1.25     ]\n",
      " [-1.4285715]\n",
      " [ 1.4285715]]\n"
     ]
    }
   ],
   "source": [
    "th_by_list = \\\n",
    "[\n",
    "  [0.8],\n",
    "  [0.7],\n",
    "  [0.3],\n",
    "]\n",
    "y_by_list = \\\n",
    "[\n",
    "  [1.],\n",
    "  [1.],\n",
    "  [0.],\n",
    "]\n",
    "\n",
    "th = tf.Variable(th_by_list, dtype=np.float32)\n",
    "y = tf.constant(y_by_list, dtype=np.float32)\n",
    "one = tf.ones_like(y)\n",
    "def j_func(th):\n",
    "  j = tf.transpose(one) @ (- y * tf.math.log(th) - (one - y) * tf.math.log(one - th)) # (th - c).T does not work in Tensorflow\n",
    "  return j\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  j = j_func(th)\n",
    "\n",
    "print('j =', j.numpy())\n",
    "\n",
    "dj_dth = tape.gradient(j, th)\n",
    "print('dj/dth =', dj_dth.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNqruxtqrpJD"
   },
   "source": [
    "## Load the data for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uopHWihGjq6U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples m = 20640\n",
      "number of columns n = 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston, load_breast_cancer, fetch_california_housing\n",
    "dataset = fetch_california_housing()\n",
    "# print(dataset.DESCR)\n",
    "# print(dataset.feature_names)\n",
    "raw_X = dataset.data # get feature data\n",
    "m, n = raw_X.shape\n",
    "y = dataset.target # get target data as a size-m 1-d array\n",
    "np_Y = y[:, np.newaxis] # convert the target data to a m x 1 2-d array\n",
    "print('number of examples m =', m)\n",
    "print('number of columns n =', n)\n",
    "\n",
    "def standardise(raw_X):\n",
    "  mu = np.mean(raw_X, axis=0, keepdims=True)\n",
    "  sigma = np.std(raw_X, axis=0, keepdims=True)\n",
    "  X_standardised = np.zeros_like(raw_X)\n",
    "  X_standardised = (raw_X - mu) / sigma  # Broadcasting is used here\n",
    "  return X_standardised \n",
    "\n",
    "def append_one_to(X_without_one):\n",
    "  X_with_one = np.pad(X_without_one, ((0, 0), (1, 0)), constant_values=1)\n",
    "  return X_with_one\n",
    "\n",
    "np_X = append_one_to(standardise(raw_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMgL86dRqEoJ"
   },
   "source": [
    "## Problem: Mean squared error (YOU NEED TO MODIFY CODES)\n",
    "$$J(\\Vec{\\theta}; \\Mat{X}, \\Vec{y}) = \\frac{1}{2} \\times \\frac{1}{m} \\sum_{i=0}^{m-1} ([\\Mat{X}]_{i, *} \\Vec{\\theta} - [\\Vec{y}]_{i})^2 = \\frac{1}{2 m}(\\Mat{X} \\Vec{\\theta} - \\Vec{y})^\\top (\\Mat{X} \\Vec{\\theta} - \\Vec{y})$$\n",
    "\n",
    "Let's implement the mean squared error in the following cell!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QtBEMdGJoMcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.8617072e-01]\n",
      " [-5.1484662e-01]\n",
      " [ 5.8099228e-01]\n",
      " [-1.9055739e-01]\n",
      " [-2.7058458e-01]\n",
      " [ 1.0614398e+00]\n",
      " [-7.2531760e-01]\n",
      " [-1.6713837e+00]\n",
      " [ 1.0598026e-03]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant(np_X, dtype=np.float32)\n",
    "Y = tf.constant(np_Y, dtype=np.float32)\n",
    "th = tf.Variable(tf.random.normal([n+1, 1], dtype=np.float32))\n",
    "print(th.numpy())\n",
    "def j_func(th):\n",
    "  j = 0.0 * (tf.reduce_sum(th, keepdims=True))\n",
    "  # modify code: correct the definition of j\n",
    "  j = (1/(2*m)) * (tf.transpose(X @ th - Y) @ (X @ th - Y))\n",
    "  # modify code: correct the definition of j\n",
    "  j = tf.squeeze(j)\n",
    "  return j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dBot5QsOqar6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j 0.2621611\n",
      "th [[ 2.0685573 ]\n",
      " [ 0.82831764]\n",
      " [ 0.11853269]\n",
      " [-0.26302058]\n",
      " [ 0.30360302]\n",
      " [-0.0045657 ]\n",
      " [-0.03928   ]\n",
      " [-0.9027036 ]\n",
      " [-0.87320536]]\n",
      "dj/dth [[-9.24183041e-07]\n",
      " [-6.08105474e-05]\n",
      " [-9.45177635e-06]\n",
      " [ 1.18592434e-04]\n",
      " [-9.97930401e-05]\n",
      " [-2.63175616e-06]\n",
      " [ 2.09522750e-06]\n",
      " [-1.25966122e-04]\n",
      " [-1.18658580e-04]]\n",
      "j 0.2621606\n",
      "th [[ 2.0685573 ]\n",
      " [ 0.8288014 ]\n",
      " [ 0.11861006]\n",
      " [-0.26395965]\n",
      " [ 0.30439055]\n",
      " [-0.00454389]\n",
      " [-0.03929686]\n",
      " [-0.90168625]\n",
      " [-0.8722454 ]]\n",
      "dj/dth [[-9.5383621e-07]\n",
      " [-3.7986050e-05]\n",
      " [-6.3102798e-06]\n",
      " [ 7.3323645e-05]\n",
      " [-6.1518593e-05]\n",
      " [-1.7866018e-06]\n",
      " [ 1.3520903e-06]\n",
      " [-8.1071834e-05]\n",
      " [-7.6432996e-05]]\n",
      "j 0.2621605\n",
      "th [[ 2.0685573 ]\n",
      " [ 0.8291042 ]\n",
      " [ 0.11866068]\n",
      " [-0.26454324]\n",
      " [ 0.30487823]\n",
      " [-0.00452944]\n",
      " [-0.0393076 ]\n",
      " [-0.901033  ]\n",
      " [-0.87162787]]\n",
      "dj/dth [[-9.6235999e-07]\n",
      " [-2.3824374e-05]\n",
      " [-4.0427658e-06]\n",
      " [ 4.5833636e-05]\n",
      " [-3.8194699e-05]\n",
      " [-1.2072322e-06]\n",
      " [ 8.3183221e-07]\n",
      " [-5.1996609e-05]\n",
      " [-4.9141177e-05]]\n",
      "j 0.26216045\n",
      "th [[ 2.0685573 ]\n",
      " [ 0.8292943 ]\n",
      " [ 0.11869344]\n",
      " [-0.26490793]\n",
      " [ 0.30518222]\n",
      " [-0.00451999]\n",
      " [-0.03931444]\n",
      " [-0.9006155 ]\n",
      " [-0.8712328 ]]\n",
      "dj/dth [[-7.9789788e-07]\n",
      " [-1.5019332e-05]\n",
      " [-2.6411726e-06]\n",
      " [ 2.8677276e-05]\n",
      " [-2.3885344e-05]\n",
      " [-8.5493139e-07]\n",
      " [ 5.4552754e-07]\n",
      " [-3.2968765e-05]\n",
      " [-3.1157531e-05]]\n",
      "j 0.26216042\n",
      "th [[ 2.0685573 ]\n",
      " [ 0.8294139 ]\n",
      " [ 0.11871437]\n",
      " [-0.26513642]\n",
      " [ 0.30537227]\n",
      " [-0.00451386]\n",
      " [-0.03931876]\n",
      " [-0.9003494 ]\n",
      " [-0.87098074]]\n",
      "dj/dth [[-8.7657827e-07]\n",
      " [-9.5249416e-06]\n",
      " [-1.6885970e-06]\n",
      " [ 1.7969223e-05]\n",
      " [-1.4919897e-05]\n",
      " [-4.6981717e-07]\n",
      " [ 3.4616016e-07]\n",
      " [-2.1137217e-05]\n",
      " [-2.0160851e-05]]\n",
      "j 0.2621603\n",
      "th [[ 2.0685573 ]\n",
      " [ 0.82948935]\n",
      " [ 0.11872799]\n",
      " [-0.26528028]\n",
      " [ 0.3054918 ]\n",
      " [-0.00450987]\n",
      " [-0.0393215 ]\n",
      " [-0.9001799 ]\n",
      " [-0.87082005]]\n",
      "dj/dth [[-9.8744567e-07]\n",
      " [-6.1110995e-06]\n",
      " [-1.0559252e-06]\n",
      " [ 1.1321490e-05]\n",
      " [-9.3901835e-06]\n",
      " [-2.9334387e-07]\n",
      " [ 2.0671422e-07]\n",
      " [-1.3673849e-05]\n",
      " [-1.2739074e-05]]\n",
      "j 0.26216045\n",
      "th [[ 2.0685573 ]\n",
      " [ 0.8295371 ]\n",
      " [ 0.11873671]\n",
      " [-0.26537088]\n",
      " [ 0.30556685]\n",
      " [-0.00450739]\n",
      " [-0.03932324]\n",
      " [-0.90007156]\n",
      " [-0.8707173 ]]\n",
      "dj/dth [[-8.9547029e-07]\n",
      " [-3.8174740e-06]\n",
      " [-7.5543721e-07]\n",
      " [ 7.0978531e-06]\n",
      " [-5.9589725e-06]\n",
      " [-2.0168886e-07]\n",
      " [ 1.3524277e-07]\n",
      " [-8.4537205e-06]\n",
      " [-7.8636549e-06]]\n",
      "j 0.2621605\n",
      "th [[ 2.0685573 ]\n",
      " [ 0.82956684]\n",
      " [ 0.11874191]\n",
      " [-0.26542777]\n",
      " [ 0.30561423]\n",
      " [-0.00450583]\n",
      " [-0.03932432]\n",
      " [-0.9000052 ]\n",
      " [-0.8706544 ]]\n",
      "dj/dth [[-8.9294736e-07]\n",
      " [-2.5384052e-06]\n",
      " [-4.3932232e-07]\n",
      " [ 4.5461611e-06]\n",
      " [-3.6937554e-06]\n",
      " [-1.2981820e-07]\n",
      " [ 8.7495266e-08]\n",
      " [-5.5467171e-06]\n",
      " [-5.0356703e-06]]\n",
      "j 0.26216054\n",
      "th [[ 2.0685573 ]\n",
      " [ 0.8295859 ]\n",
      " [ 0.11874532]\n",
      " [-0.26546374]\n",
      " [ 0.30564395]\n",
      " [-0.00450489]\n",
      " [-0.03932501]\n",
      " [-0.899962  ]\n",
      " [-0.87061334]]\n",
      "dj/dth [[-8.8179149e-07]\n",
      " [-1.4867874e-06]\n",
      " [-2.8473005e-07]\n",
      " [ 2.8133434e-06]\n",
      " [-2.4355909e-06]\n",
      " [-6.6600819e-08]\n",
      " [ 5.2095800e-08]\n",
      " [-3.6123456e-06]\n",
      " [-3.2883163e-06]]\n",
      "j 0.26216063\n",
      "th [[ 2.0685573 ]\n",
      " [ 0.8295981 ]\n",
      " [ 0.11874764]\n",
      " [-0.26548648]\n",
      " [ 0.30566278]\n",
      " [-0.00450415]\n",
      " [-0.03932546]\n",
      " [-0.89993405]\n",
      " [-0.8705869 ]]\n",
      "dj/dth [[-9.1750189e-07]\n",
      " [-9.0604408e-07]\n",
      " [-1.5199839e-07]\n",
      " [ 1.8743076e-06]\n",
      " [-1.5511785e-06]\n",
      " [-4.4322860e-08]\n",
      " [ 5.2591361e-08]\n",
      " [-2.2578533e-06]\n",
      " [-2.1029573e-06]]\n",
      "j 0.2621605\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "n_steps = 1000\n",
    "display_interval = 100\n",
    "for i_step in range(n_steps): \n",
    "  with tf.GradientTape() as tape:\n",
    "    j = j_func(th)\n",
    "\n",
    "  dj_dth = tape.gradient(j, th)\n",
    "\n",
    "  optimizer.apply_gradients(zip([dj_dth], [th])) # update using gradient\n",
    "\n",
    "  if i_step % display_interval == 0:\n",
    "    print('j', j.numpy())\n",
    "    print('th', th.numpy())\n",
    "    print('dj/dth', dj_dth.numpy())\n",
    "\n",
    "j = j_func(th)\n",
    "print('j', j.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7aHAb1vo5Rj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "comp-1801-20201016-01-student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
