{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzI1Jzm1xDqb"
   },
   "source": [
    "# Vectorisation and Gradient Descent\n",
    "- COMP 1801 IT lab: 09 Oct 2020\n",
    "$\\newcommand{\\Vec}[1]{\\boldsymbol{#1}}$\n",
    "$\\newcommand{\\Mat}[1]{\\boldsymbol{#1}}$\n",
    "## Aim\n",
    "- Learn the ability vectorisation notation and the ability to convert equations to a modern language code such as Numpy\n",
    "- Learn how effective vectorisation is.\n",
    "- Learn how gradient descent works \n",
    "## Note to execute a cell, press SHIFT + ENTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnol6g1GQQpV"
   },
   "source": [
    "## Notation\n",
    "- $\\mathbb{R}$: the set of real numbers\n",
    "- $\\mathbb{R}^{m \\times n}$: the set of matrices of size $m \\times n$\n",
    "- $\\mathbb{R}^{m}$: the set of $m$ dimensional real vectors, or matrices of $m \\times n$ &emsp; ($\\mathbb{R}^{m} = \\mathbb{R}^{m \\times 1}$)\n",
    "- Bold upper case (e.g. $\\Mat{A}$): a matrix\n",
    "$$\n",
    "\\Mat{A} \n",
    "= \\begin{bmatrix}\n",
    "a_{0,0} & a_{0,1} & \\cdots & a_{0,n-1} \\\\\n",
    "a_{1,0} & a_{1,1} & \\cdots & a_{1,n-1} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{m-1,0} & a_{m-1,1} & \\cdots & a_{m-1,n-1} \\\\\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{m \\times n}\n",
    "$$\n",
    "- Bold lower case (e.g. $\\Vec{v}$): a vector (a matrix whose column size is one)\n",
    "$$\n",
    "\\Vec{v} \n",
    "= \\begin{bmatrix}\n",
    "v_{0,0} \\\\\n",
    "v_{1,0} \\\\\n",
    "\\vdots \\\\\n",
    "v_{m-1,0} \\\\\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{m \\times 1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHlBo-1Uj_B9"
   },
   "source": [
    "## Import libraries. Do not forget!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iumflHIajP35"
   },
   "outputs": [],
   "source": [
    "# Import NumPy, which can deal with multi-dimensional arrays such as matrix intuitively.\n",
    "import numpy as np\n",
    "\n",
    "# For elapsed time measurement.\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dh3T7QunjGAR"
   },
   "source": [
    "## Element notation\n",
    "- $[\\Mat{A}]_{i,j}$ denotes the element in the $i$-th row and $j$-th column of the matrix $\\Mat{A}$.\n",
    "- $\\mathtt{A[i,j]}$ is the element in the $i$-th row and $j$-th column of the Numpy 2d-array $\\mathtt{A}$.\n",
    "- $[\\Mat{A}]_{i,*}$ denotes the $i$-th row of the matrix $\\Mat{A}$.\n",
    "- $\\mathtt{A[i,:]}$ is the Numpy 1d-array given by the $i$-th row of the Numpy 2d-array $\\mathtt{A}$.\n",
    "- $[\\Mat{A}]_{*,j}$ denotes the $j$-th column of the matrix $\\Mat{A}$.\n",
    "- $\\mathtt{A[:,j]}$ is the Numpy 1d-array given by the $j$-th column of the Numpy 2d-array $\\mathtt{A}$.\n",
    "- $[\\Mat{v}]_{i}$ denotes the $i$-th element of the vector $\\Vec{v}$, or the element in the $i$-th row and $0$-th column of the \"matrix\" $\\Vec{v}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "eADyTATyXdTz",
    "outputId": "b87e1c05-1019-4b26-afea-364623a26b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "A[1,3]=\n",
      "7\n",
      "A[2,1]=\n",
      "9\n",
      "A[1, :]=\n",
      "[4 5 6 7]\n",
      "A[2, :]=\n",
      "[ 8  9 10 11]\n",
      "A[:, 0]=\n",
      "[0 4 8]\n",
      "A[:, 2]=\n",
      "[ 2  6 10]\n",
      "A[:, :]=\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(12).reshape([3, 4])\n",
    "print('A=')\n",
    "print(A)\n",
    "print('A[1,3]=')\n",
    "print(A[1,3])\n",
    "print('A[2,1]=')\n",
    "print(A[2,1])\n",
    "print('A[1, :]=')\n",
    "print(A[1, :])\n",
    "print('A[2, :]=')\n",
    "print(A[2, :])\n",
    "print('A[:, 0]=')\n",
    "print(A[:, 0])\n",
    "print('A[:, 2]=')\n",
    "print(A[:, 2])\n",
    "print('A[:, :]=')\n",
    "print(A[:, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6WqJiqJXU4K"
   },
   "source": [
    "## Element-wise comparison\n",
    "- $\n",
    "[\\Mat{A}=\\Mat{B}]_{i,j} :=\n",
    "\\begin{cases} \n",
    "\\mathrm{True}, & \\textrm{if $[\\Mat{A}]_{i,j} = [\\Mat{B}]_{i,j}$} \\\\\n",
    "\\mathrm{False}, & \\textrm{if $[\\Mat{A}]_{i,j} \\ne [\\Mat{B}]_{i,j}$} \\\\\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "- $\n",
    "\\mathtt{(A==B)[i,j]} :=\n",
    "\\begin{cases} \n",
    "\\mathrm{True}, & \\textrm{if $\\mathtt{A[i,j]} = \\mathtt{B[i,j]}$} \\\\\n",
    "\\mathrm{False}, & \\textrm{if $\\mathtt{A[i,j]} \\ne \\mathtt{B[i,j]}$} \\\\\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "pfdZ8vGPkP7_",
    "outputId": "fa9e66d0-ad29-4ffb-edbc-da7adf3b4762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O =\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "I =\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "(O==I) =\n",
      "[[False  True  True  True]\n",
      " [ True False  True  True]\n",
      " [ True  True False  True]\n",
      " [ True  True  True False]]\n"
     ]
    }
   ],
   "source": [
    "O = np.zeros([4, 4]) # 4 x 4 zero matrix\n",
    "I = np.eye(4, 4) # 4 x 4 identity matrix\n",
    "print('O =')\n",
    "print(O)\n",
    "print('I =')\n",
    "print(I)\n",
    "print('(O==I) =')\n",
    "print(O==I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWB4Vt5zsyfw"
   },
   "source": [
    "## Applying scalar function to matrix\n",
    "Let $\\Mat{A} \\in \\mathbb{R}^{m \\times n}$, and $f: \\mathbb{R} \\to \\mathbb{R}$.\n",
    "- $[f(\\Mat{A})]_{i, j} := f([\\Mat{A}]_{i, j})$, for $i = 0, 1, \\dots, m-1$, $j = 0, 1, \\dots, n-1$.\n",
    "- $\\mathtt{f(A)[i, j]} := \\mathtt{f(A[i, j])}$, for $\\mathtt{i} = \\mathtt{0, 1, \\dots, m-1}$, $\\mathtt{j} = \\mathtt{0, 1, \\dots, n-1}$.\n",
    "\n",
    "Let $\\Mat{A}, \\Mat{B} \\in \\mathbb{R}^{m \\times n}$, and $g: \\mathbb{R} \\times \\mathbb{R} \\to \\mathbb{R}$.\n",
    "- $[g(\\Mat{A}, \\Mat{B})]_{i, j} := g([\\Mat{A}]_{i, j}, [\\Mat{B}]_{i, j})$, for $i = 0, 1, \\dots, m-1$, $j = 0, 1, \\dots, n-1$.\n",
    "- $\\mathtt{g(A, B)[i, j]} := \\mathtt{g(A[i, j], B[i, j])}$, for $\\mathtt{i} = \\mathtt{0, 1, \\dots, m-1}$, $\\mathtt{j} = \\mathtt{0, 1, \\dots, n-1}$.\n",
    "\n",
    "In particular, for $i = 0, 1, \\dots, m-1$, $j = 0, 1, \\dots, n-1$.\n",
    "- $[\\Mat{A} + \\Mat{B}]_{i, j} := [\\Mat{A}]_{i, j} + [\\Mat{B}]_{i, j}$\n",
    "- $\\mathtt{(A + B)[i, j]} := \\mathtt{A[i, j] + B[i, j]}$\n",
    "- $[\\Mat{A} - \\Mat{B}]_{i, j} := [\\Mat{A}]_{i, j} - [\\Mat{B}]_{i, j}$\n",
    "- $\\mathtt{(A - B)[i, j]} := \\mathtt{A[i, j] - B[i, j]}$\n",
    "- $[\\Mat{A} \\otimes \\Mat{B}]_{i, j} := [\\Mat{A}]_{i, j} [\\Mat{B}]_{i, j}$\n",
    "- $\\mathtt{(A * B)[i, j]} := \\mathtt{A[i, j] * B[i, j]}$\n",
    "- $[\\Mat{A} \\oslash \\Mat{B}]_{i, j} := [\\Mat{A}]_{i, j} / [\\Mat{B}]_{i, j}$\n",
    "- $\\mathtt{(A / B)[i, j]} := \\mathtt{A[i, j] / B[i, j]}$\n",
    "\n",
    "Note: $\\otimes$ and $\\oslash$ denote elementwise multiplication and division, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "iMe8GPDYwHxa",
    "outputId": "fc3ec8cf-01e0-4216-a4db-5ba7b084e5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "[[ 3.29820962 -0.13911757  0.02806456 -0.08045294 -1.86337893]\n",
      " [ 0.03277366  0.85766287  0.93486734  0.00474801  1.34425803]\n",
      " [ 0.44096288  1.1310595   0.58176423  0.66834353  0.82292006]]\n",
      "f(A) =\n",
      "[[-0.15597748 -0.13866926  0.02806087 -0.08036617 -0.95750218]\n",
      " [ 0.03276779  0.75631566  0.8045203   0.00474799  0.97444975]\n",
      " [ 0.42681043  0.90486373  0.54949879  0.61968676  0.73313484]]\n",
      "f(A) computed elementwisely\n",
      "[[-0.15597748 -0.13866926  0.02806087 -0.08036617 -0.95750218]\n",
      " [ 0.03276779  0.75631566  0.8045203   0.00474799  0.97444975]\n",
      " [ 0.42681043  0.90486373  0.54949879  0.61968676  0.73313484]]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "  return np.sin(x)\n",
    "m = 3\n",
    "n = 5\n",
    "A = np.random.normal(size=[m, n]) # m x n random matrix\n",
    "f_A_for = np.zeros([3, 5])\n",
    "for i in range(m):\n",
    "  for j in range(n):\n",
    "    f_A_for[i, j] = f(A[i, j])\n",
    "print('A =')\n",
    "print(A)\n",
    "print('f(A) =')\n",
    "print(f(A))\n",
    "print('f(A) computed elementwisely')\n",
    "print(f_A_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Rc8Qu7AXksb"
   },
   "source": [
    "## Basic operation for a matrix\n",
    "Let $c \\in \\mathbb{R}, \\Mat{A} \\in \\mathbb{R}^{m \\times n}$. $\\mathtt{A.shape = (m, n)}$\n",
    "- Scalar product $c \\Mat{A}$ is given by $[c \\Mat{A}]_{i,j} := c[\\Mat{A}]_{i,j}$, for $i = 0, 1, \\dots, m-1$, $j = 0, 1, \\dots, n-1$.\n",
    "- Scalar product $\\mathtt{c * A}$ is given by $\\mathtt{(c * A) [i, j]} := \\mathtt{c * A [i, j]}$, for $\\mathtt{i} = \\mathtt{0, 1, \\dots, m-1}$, $\\mathtt{j} = \\mathtt{0, 1, \\dots, n-1}$.\n",
    "- The transpose $\\Mat{A}^{\\top} \\in \\mathbb{R}^{n \\times m}$ is given by $[\\Mat{A}^{\\top}]_{j,i} := [\\Mat{A}]_{i,j}$, for $i = 0, 1, \\dots, m-1$, $j = 0, 1, \\dots, n-1$.\n",
    "- The transpose $\\mathtt{A.T}$, where $\\mathtt{A.T.shape = (n, m)}$ is given by $\\mathtt{(A.T) [j, i]} := \\mathtt{A [i, j]}$, for $\\mathtt{i} = \\mathtt{0, 1, \\dots, m-1}$, $\\mathtt{j} = \\mathtt{0, 1, \\dots, n-1}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suTisnZXFqhi"
   },
   "source": [
    "## Broadcasting\n",
    "Let \n",
    "- $\\Mat{A, B} \\in \\mathbb{R}^{m \\times n}$, $\\Vec{u} \\in \\mathbb{R}^{m \\times 1}$, $\\Vec{v} \\in \\mathbb{R}^{n \\times 1}$, and $c \\in \\mathbb{R}^{1 \\times 1}$,\n",
    "- $\\mathtt{A.shape} = \\mathtt{(m, n)}$, $\\mathtt{B.shape} = \\mathtt{(m, n)}$, $\\mathtt{u.shape} = \\mathtt{(m, 1)}$, $\\mathtt{v.shape} = \\mathtt{(n, 1)}$, $\\mathtt{c.shape} = \\mathtt{(1, 1)}$,\n",
    "- $f: \\mathbb{R}^{m \\times n} \\times \\mathbb{R}^{m \\times n} \\to \\mathbb{R}^{1 \\times 1}, \\mathbb{R}^{m \\times 1}, \\mathbb{R}^{1 \\times n}, \\textrm{ or } \\mathbb{R}^{m \\times n}$, \n",
    "- $\\mathtt{f(A,B).shape} = \\mathtt{(1, 1)}$, $\\mathtt{(m, 1)}$, $\\mathtt{(1, n)}$, or $\\mathtt{(m, n)}$.\n",
    "\n",
    "Then\n",
    "- $f(\\Mat{A}, \\Vec{u}^\\top) := f(\\Mat{A}, \\Vec{u}^\\top \\Vec{1}_{n \\times 1})$,\n",
    "- $\\mathtt{f(A, u.T)} := \\mathtt{f(A, u.T\\ @\\ np.ones([n, 1]))}$,\n",
    "- $f(\\Mat{A}, \\Vec{v}) := f(\\Mat{A}, \\Vec{1}_{m \\times 1}^\\top \\Vec{v})$,\n",
    "- $\\mathtt{f(A, v)} := \\mathtt{f(A, np.ones([m, 1]).T\\ @\\ v)}$,\n",
    "- $f(\\Mat{A}, c) := f(\\Mat{A}, \\Vec{1}_{m \\times 1}^\\top c \\Vec{1}_{n \\times 1})$,\n",
    "- $\\mathtt{f(A, c)} := \\mathtt{f(A, np.ones([m, 1]).T\\ @\\ c\\ @ \\ np.ones([1, n]))}$,\n",
    "- $f(\\Vec{u}^\\top, \\Mat{B}) := f(\\Vec{u}^\\top \\Vec{1}_{n \\times 1}, \\Mat{B})$,\n",
    "- $\\mathtt{f(u.T, B)} := \\mathtt{f(u.T\\ @\\ np.ones([n, 1]), B)}$,\n",
    "- $f(\\Vec{v}, \\Mat{B}) := f(\\Vec{1}_{m \\times 1}^\\top \\Vec{v}, \\Mat{B})$,\n",
    "- $\\mathtt{f(v, B)} := \\mathtt{f(np.ones([m, 1]).T\\ @\\ v, B)}$,\n",
    "- $f(c, \\Mat{B}) := f(\\Vec{1}_{m \\times 1}^\\top c \\Vec{1}_{n \\times 1}, \\Mat{B})$,\n",
    "- $\\mathtt{f(c, B)} := \\mathtt{f(np.ones([m, 1]).T\\ @\\ c\\ @ \\ np.ones([1, n]), B)}$,\n",
    "- $f(\\Vec{u}^\\top, \\Vec{v}) := f(\\Vec{u} \\Vec{1}_{1 \\times n}, \\Vec{1}_{m \\times 1}^\\top \\Vec{v})$,\n",
    "- $\\mathtt{f(u.T, v)} := \\mathtt{f(u.T\\ @\\ np.ones([n, 1]), np.ones([n, 1])\\ @\\ v)}$,\n",
    "- $f(\\Vec{v}, \\Vec{u}^\\top) := f(\\Vec{1}_{m \\times 1}^\\top \\Vec{v}, \\Vec{u} \\Vec{1}_{1 \\times n})$,\n",
    "- $\\mathtt{f(v, u.T)} := \\mathtt{f(np.ones([n, 1])\\ @\\ v, u.T\\ @\\ np.ones([n, 1]))}$,\n",
    "\n",
    "In particular, $f$ can be $\\mathtt{+, -, *, /}$\n",
    "- $\\Mat{A} + \\Vec{u}^\\top := \\Mat{A} + \\Vec{u}^\\top \\Vec{1}_{n \\times 1}$,\n",
    "- $\\mathtt{A + u.T} := \\mathtt{A + u.T\\ @\\ np.ones([n, 1])}$,\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "d9jD_NLFQK9_",
    "outputId": "1aff947c-2af6-4157-b6f6-fbe799f691c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u.T =\n",
      "[[0 1 2]]\n",
      "v =\n",
      "[[3]\n",
      " [7]]\n",
      "u.T * v =\n",
      "[[ 0  3  6]\n",
      " [ 0  7 14]]\n"
     ]
    }
   ],
   "source": [
    "u = np.array([[0], [1], [2]])\n",
    "v = np.array([[3], [7]])\n",
    "print('u.T =')\n",
    "print(u.T)\n",
    "print('v =')\n",
    "print(v)\n",
    "print('u.T * v =')\n",
    "print(u.T * v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZVmeNHJjDn8"
   },
   "source": [
    "## Matrix product (dot product)\n",
    "Let $\\Mat{A} \\in \\mathbb{R}^{m \\times l}, \\Mat{B} \\in \\mathbb{R}^{l \\times n}$, or $\\mathtt{A.shape} = \\mathtt{(m, l)}$, $\\mathtt{B.shape} = \\mathtt{(l, n)}$\n",
    "- $[\\Mat{A} \\Mat{B}]_{i, j} := \\sum_{k=0}^{l-1} [\\Mat{A}]_{i, k} [\\Mat{B}]_{k, j}$, for $i = 0, 1, \\dots, m-1$, $j = 0, 1, \\dots, n-1$.\n",
    "- $\\mathtt{(A @ B)[i, j]} := \\mathtt{np.sum(A[i, :] * B[:, j])}$, for $\\mathtt{i} = \\mathtt{0, 1, \\dots, m-1}$, $\\mathtt{j} = \\mathtt{0, 1, \\dots, n-1}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "374ly8WHswYI",
    "outputId": "9700cc2b-6709-439b-f0ed-55f2ca4b8b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "[[ 0.84984235  2.3562961   1.21184383 -1.15406302]\n",
      " [-0.45041103 -0.10135864  0.30202544 -0.66442109]\n",
      " [-0.16571271 -0.38960072  2.07519267  0.776192  ]]\n",
      "B =\n",
      "[[ 0.37391897 -1.5020347  -0.48967232 -2.18566859 -0.42205756]\n",
      " [ 0.99895176 -0.63280997  0.62397891 -0.55025812 -0.21312366]\n",
      " [ 1.28816385 -2.70644209 -0.27749339  0.062265    0.1594035 ]\n",
      " [-0.28977743 -0.9469976   0.96093925 -2.77336667 -0.26781403]]\n",
      "A @ B =\n",
      "[[ 4.56707314 -4.95447062 -0.39112831  0.12205057 -0.35861841]\n",
      " [ 0.31192288  0.55246457 -0.56497021  2.9017116   0.43778651]\n",
      " [ 1.99710982 -5.8559913   0.00806341 -1.4468791   0.27589131]]\n",
      "AB computed by the for for sum strategy =\n",
      "[[ 4.56707314 -4.95447062 -0.39112831  0.12205057 -0.35861841]\n",
      " [ 0.31192288  0.55246457 -0.56497021  2.9017116   0.43778651]\n",
      " [ 1.99710982 -5.8559913   0.00806341 -1.4468791   0.27589131]]\n",
      "AB computed by the for for for strategy =\n",
      "[[ 4.56707314 -4.95447062 -0.39112831  0.12205057 -0.35861841]\n",
      " [ 0.31192288  0.55246457 -0.56497021  2.9017116   0.43778651]\n",
      " [ 1.99710982 -5.8559913   0.00806341 -1.4468791   0.27589131]]\n"
     ]
    }
   ],
   "source": [
    "m = 3\n",
    "n = 5\n",
    "l = 4\n",
    "A = np.random.normal(size=[m, l]) # m x l random matrix\n",
    "B = np.random.normal(size=[l, n]) # l x n random matrix\n",
    "AB_at = A @ B\n",
    "AB_for_for_sum = np.zeros([m, n])\n",
    "for i in range(m):\n",
    "  for j in range(n):\n",
    "    AB_for_for_sum[i, j] = np.sum(A[i, :] * B[:, j])\n",
    "AB_for_for_for = np.zeros([3, 5])\n",
    "for i in range(m):\n",
    "  for j in range(n):\n",
    "    for k in range(l):\n",
    "      AB_for_for_for[i, j] += np.sum(A[i, k] * B[k, j])\n",
    "print('A =')\n",
    "print(A)\n",
    "print('B =')\n",
    "print(B)\n",
    "print('A @ B =')\n",
    "print(AB_at)\n",
    "print('AB computed by the for for sum strategy =')\n",
    "print(AB_for_for_sum)\n",
    "print('AB computed by the for for for strategy =')\n",
    "print(AB_for_for_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnU9w9AUTRO5"
   },
   "source": [
    "## Efficiency of vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "WUztHDKARBSO",
    "outputId": "a0f34380-9695-4912-b6a3-5afac7f53854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for A @ B =\n",
      "9.72747802734375e-05\n",
      "Elapsed time for the for for for strategy =\n",
      "0.30290699005126953\n"
     ]
    }
   ],
   "source": [
    "m = 30\n",
    "n = 50\n",
    "l = 40\n",
    "A = np.random.normal(size=[m, l]) # m x l random matrix\n",
    "B = np.random.normal(size=[l, n]) # l x n random matrix\n",
    "\n",
    "start_time_AB_at = time.time()\n",
    "AB_at = A @ B\n",
    "end_time_AB_at = time.time()\n",
    "elapsed_time_AB_at = end_time_AB_at - start_time_AB_at\n",
    "print('Elapsed time for A @ B =')\n",
    "print(elapsed_time_AB_at)\n",
    "\n",
    "start_time_AB_for_for_for = time.time()\n",
    "AB_for_for_for = np.zeros([m, n])\n",
    "for i in range(m):\n",
    "  for j in range(n):\n",
    "    for k in range(l):\n",
    "      AB_for_for_for[i, j] += np.sum(A[i, k] * B[k, j])\n",
    "end_time_AB_for_for_for = time.time()\n",
    "elapsed_time_AB_for_for_for = end_time_AB_for_for_for - start_time_AB_for_for_for\n",
    "\n",
    "print('Elapsed time for the for for for strategy =')\n",
    "print(elapsed_time_AB_for_for_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL7-QHxz9OAw"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "a2CP7ctM4ptS",
    "outputId": "03d03358-5f3e-4c7e-c434-48c48b973e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples m = 20640\n",
      "number of columns n = 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston, load_breast_cancer, fetch_california_housing\n",
    "dataset = fetch_california_housing()\n",
    "# print(dataset.DESCR)\n",
    "# print(dataset.feature_names)\n",
    "raw_X = dataset.data # get feature data\n",
    "m, n = raw_X.shape\n",
    "y = dataset.target # get target data as a size-m 1-d array\n",
    "Y = y[:, np.newaxis] # convert the target data to a m x 1 2-d array\n",
    "print('number of examples m =', m)\n",
    "print('number of columns n =', n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yHUojHg7Exp5"
   },
   "outputs": [],
   "source": [
    "def standardise(raw_X):\n",
    "  mu = np.mean(raw_X, axis=0, keepdims=True)\n",
    "  sigma = np.std(raw_X, axis=0, keepdims=True)\n",
    "  X_standardised = np.zeros_like(raw_X)\n",
    "\n",
    "  # Modify the code - correct definition of X_standardised: start\n",
    "\n",
    "  # X_standardised = \n",
    "\n",
    "  # Modify the code: end\n",
    "\n",
    "  X_standardised = (raw_X - mu) / sigma  # Broadcasting is used here\n",
    "  return X_standardised \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alsjf3awDc-N"
   },
   "source": [
    "## Standardisation (YOU NEED TO MODIFY CODE)\n",
    "\n",
    "### Mean\n",
    "- $\\mathtt{np.mean(A, axis=0, keepdims=True).shape} = \\mathtt{(1, n)}$\n",
    "- $\\mathtt{np.mean(A, axis=0, keepdims=True)[0, j]}$ is the mean of all the elements in the $\\mathtt{j}$-th column of matrix $\\mathtt{A}$.\n",
    "- $\\mathtt{np.mean(A, axis=1, keepdims=True).shape} = \\mathtt{(m, 1)}$\n",
    "- $\\mathtt{np.mean(A, axis=1, keepdims=True)[i, 0]}$ is the mean of all the elements in the $\\mathtt{i}$-th row of matrix $\\mathtt{A}$.\n",
    "\n",
    "### Standard deviation\n",
    "- $\\mathtt{np.std(A, axis=0, keepdims=True).shape} = \\mathtt{(1, n)}$\n",
    "- $\\mathtt{np.std(A, axis=0, keepdims=True)[0, j]}$ is the standard deviation of all the elements in the $\\mathtt{j}$-th column of matrix $\\mathtt{A}$.\n",
    "- $\\mathtt{np.std(A, axis=1, keepdims=True).shape} = \\mathtt{(m, 1)}$\n",
    "- $\\mathtt{np.std(A, axis=1, keepdims=True)[i, 0]}$ is the standard deviation of all the elements in the $\\mathtt{i}$-th row of matrix $\\mathtt{A}$.\n",
    "\n",
    "Let's implement the standardisation in the following cell! For the $j$-th column vector $\\tilde{\\Vec{x}}_{j}$, the standardised vector $\\tilde{\\Vec{x}}_{j}^\\mathrm{standardised}$ is given by \n",
    "$$ \\tilde{\\Vec{x}}^\\mathrm{standardised}_{j} := (\\tilde{\\Vec{x}}_{j} - \\Vec{1}_{m} \\mu_{j}) \\oslash (\\Vec{1}_{m} \\sigma_{j}),$$\n",
    "where $\\mu_{j}$ is the mean of $\\tilde{\\Vec{x}}_{j}$, and $\\sigma_{j}$ is the standard deviation of $\\tilde{\\Vec{x}}_{j}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oaspcA8YzIj"
   },
   "source": [
    "## Appending one vector to the feature matrix. (corresponding to $\\theta_{0}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BilAW6WeYtSv"
   },
   "outputs": [],
   "source": [
    "def append_one_to(X_without_one):\n",
    "  X_with_one = np.pad(X_without_one, ((0, 0), (1, 0)), constant_values=1)\n",
    "  return X_with_one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_Ep3ArrdhRJ"
   },
   "source": [
    "## Now, preprocess our feature data matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kPI8fkkedn-J"
   },
   "outputs": [],
   "source": [
    "X = append_one_to(standardise(raw_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKlS3oHSTv-t"
   },
   "source": [
    "## Mean squared error (YOU NEED TO MODIFY CODES)\n",
    "$$J(\\Vec{\\theta}; \\Mat{X}, \\Vec{y}) = \\frac{1}{2} \\times \\frac{1}{m} \\sum_{i=0}^{m-1} ([\\Mat{X}]_{i, *} \\Vec{\\theta} - [\\Vec{y}]_{i})^2 = \\frac{1}{2 m}(\\Mat{X} \\Vec{\\theta} - \\Vec{y})^\\top (\\Mat{X} \\Vec{\\theta} - \\Vec{y})$$\n",
    "\n",
    "Let's implement the mean squared error in the following cell!\n",
    "- Advanced: Do you have a way to implement it without using $m$ or $n$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cD83y2wT6GGx"
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(Theta, X, Y):\n",
    "  m, n = X.shape\n",
    "\n",
    "  mse_matrix = 100000000000 * np.ones([1, 1]) # result of the mse should be 1 x 1 matrix\n",
    "\n",
    "  # Modify the code - correct definition of mse_matrix: start\n",
    "\n",
    "  \n",
    "  #mse_matrix =  ((1/2) * (1/m)) * ((X @ Theta - Y). T @ (X @ Theta - Y))\n",
    "  mse_matrix = (1/(2*m)) * ((X @ Theta - Y).T @ (X @ Theta - Y))\n",
    "  \n",
    "\n",
    "  # Modify the code: end\n",
    "\n",
    "  mse_scalar = np.squeeze(mse_matrix) # convert a 1 x 1 matrix to scalar \n",
    "  return mse_scalar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGp-VzcLS_Jv"
   },
   "source": [
    "## Let's calculate the loss function! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4CNqxPOaDcSm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current parameter Theta\n",
      "[[0.1]\n",
      " [0.1]\n",
      " [0.1]\n",
      " [0.1]\n",
      " [0.1]\n",
      " [0.1]\n",
      " [0.1]\n",
      " [0.1]\n",
      " [0.1]]\n",
      "Cost function MSE\n",
      "2.561821183325288\n",
      "Hopefully, you get around 2.5618\n",
      "Current parameter Theta\n",
      "[[0.2]\n",
      " [0.2]\n",
      " [0.2]\n",
      " [0.2]\n",
      " [0.2]\n",
      " [0.2]\n",
      " [0.2]\n",
      " [0.2]\n",
      " [0.2]]\n",
      "Cost function MSE\n",
      "2.3976898863719383\n",
      "Hopefully, you get around 2.3977\n"
     ]
    }
   ],
   "source": [
    "def calc_mse(Theta, X, Y):\n",
    "  print('Current parameter Theta')\n",
    "  print(Theta)\n",
    "  mse = mean_squared_error(Theta, X, Y)\n",
    "  print('Cost function MSE')\n",
    "  print(mse)\n",
    "  return mse\n",
    "\n",
    "Theta = 0.1 * np.ones([9, 1])\n",
    "calc_mse(Theta, X, Y)\n",
    "print('Hopefully, you get around', 2.5618)\n",
    "Theta = 0.2 * np.ones([9, 1])\n",
    "calc_mse(Theta, X, Y)\n",
    "print('Hopefully, you get around', 2.3977)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QB-OYlgVap9x"
   },
   "source": [
    "## Gradient computation (YOU NEED TO MODIFY CODES)\n",
    "In linear regression, the gradient is given by\n",
    "$$ \\frac{\\partial}{\\partial \\Vec{\\theta}} J (\\Vec{\\theta}) = \\frac{1}{m} (\\Mat{X}^\\top \\Mat{X} \\Vec{\\theta} - \\Mat{X}^\\top \\Vec{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kz-gZCqjas4u"
   },
   "outputs": [],
   "source": [
    "def get_gradient(Theta, X, Y):\n",
    "  m, n = X.shape\n",
    "  gradient_of_Theta = np.zeros_like(Theta)\n",
    "\n",
    "  # Modify the code - correct definition of gradient_of_Theta: start\n",
    "  # gradient_of_Theta = (1/m) * (X.T @ X @ Theta - X.T @ Y)\n",
    "  gradient_of_Theta = (1/m)* (X. T @ X @ Theta - X. T @ Y )\n",
    "  \n",
    "  # Modify the code: end\n",
    "\n",
    "  return gradient_of_Theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Le14gSq1gYrZ"
   },
   "source": [
    "## Update the parameter along the gradient (YOU NEED TO MODIFY CODES)\n",
    "$$ \\Vec{\\theta} \\gets \\Vec{\\theta} - \\lambda \\frac{\\partial}{\\partial \\Vec{\\theta}} J (\\Vec{\\theta}), $$\n",
    "where $\\lambda$ is the learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "z1L-wOjkW68J"
   },
   "outputs": [],
   "source": [
    "def gradient_descent_update(Theta, X, Y, learning_rate):\n",
    "  Theta_new = np.zeros_like(Theta)\n",
    "  gradient_of_Theta = get_gradient(Theta, X, Y)\n",
    "\n",
    "  # Modify the code - correct definition of Theta_new: start\n",
    "\n",
    "  Theta_new = Theta - learning_rate * gradient_of_Theta\n",
    "\n",
    "  # Modify the code: end\n",
    "  return Theta_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlINcPd4hLP7"
   },
   "source": [
    "## Let's execute the gradient descent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HpFEqEMYWOqY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current parameter Theta\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Cost function MSE\n",
      "2.8052415994936264\n",
      "100 -th iteration.\n",
      "Current parameter Theta\n",
      "[[ 2.06850323]\n",
      " [ 0.81682107]\n",
      " [ 0.17679998]\n",
      " [-0.12801589]\n",
      " [ 0.14202428]\n",
      " [ 0.01663505]\n",
      " [-0.04392645]\n",
      " [-0.48692142]\n",
      " [-0.45059052]]\n",
      "Cost function MSE\n",
      "0.2764460864036497\n",
      "200 -th iteration.\n",
      "Current parameter Theta\n",
      "[[ 2.06855817]\n",
      " [ 0.83914273]\n",
      " [ 0.14724148]\n",
      " [-0.23357274]\n",
      " [ 0.25730724]\n",
      " [ 0.00573741]\n",
      " [-0.04193931]\n",
      " [-0.6832587 ]\n",
      " [-0.65260618]]\n",
      "Cost function MSE\n",
      "0.26543131496920164\n",
      "300 -th iteration.\n",
      "Current parameter Theta\n",
      "[[ 2.06855817e+00]\n",
      " [ 8.43400811e-01]\n",
      " [ 1.33081686e-01]\n",
      " [-2.69595327e-01]\n",
      " [ 2.99398803e-01]\n",
      " [ 5.31172189e-04]\n",
      " [-4.08323317e-02]\n",
      " [-7.82482676e-01]\n",
      " [-7.53679217e-01]]\n",
      "Cost function MSE\n",
      "0.2629947469822588\n",
      "400 -th iteration.\n",
      "Current parameter Theta\n",
      "[[ 2.06855817e+00]\n",
      " [ 8.41762271e-01]\n",
      " [ 1.26190525e-01]\n",
      " [-2.78813979e-01]\n",
      " [ 3.12437411e-01]\n",
      " [-1.95446495e-03]\n",
      " [-4.02144530e-02]\n",
      " [-8.34255784e-01]\n",
      " [-8.05857347e-01]]\n",
      "Cost function MSE\n",
      "0.2624023163459268\n",
      "500 -th iteration.\n",
      "Current parameter Theta\n",
      "[[ 2.06855817]\n",
      " [ 0.83881422]\n",
      " [ 0.12274148]\n",
      " [-0.27866126]\n",
      " [ 0.31469346]\n",
      " [-0.00317091]\n",
      " [-0.03985983]\n",
      " [-0.86216662]\n",
      " [-0.83368713]]\n",
      "Cost function MSE\n",
      "0.26223945721866276\n",
      "600 -th iteration.\n",
      "Current parameter Theta\n",
      "[[ 2.06855817]\n",
      " [ 0.83610541]\n",
      " [ 0.12096053]\n",
      " [-0.27592451]\n",
      " [ 0.31347757]\n",
      " [-0.00378364]\n",
      " [-0.03965142]\n",
      " [-0.8776929 ]\n",
      " [-0.84901332]]\n",
      "Cost function MSE\n",
      "0.2621886603630796\n",
      "700 -th iteration.\n",
      "Current parameter Theta\n",
      "[[ 2.06855817]\n",
      " [ 0.83401901]\n",
      " [ 0.12001041]\n",
      " [-0.27302797]\n",
      " [ 0.31154212]\n",
      " [-0.00410219]\n",
      " [-0.03952656]\n",
      " [-0.88657815]\n",
      " [-0.85770632]]\n",
      "Cost function MSE\n",
      "0.2621711089275463\n",
      "800 -th iteration.\n",
      "Current parameter Theta\n",
      "[[ 2.06855817]\n",
      " [ 0.83253427]\n",
      " [ 0.11948706]\n",
      " [-0.27068098]\n",
      " [ 0.30980287]\n",
      " [-0.00427331]\n",
      " [-0.03945063]\n",
      " [-0.89178748]\n",
      " [-0.86276501]]\n",
      "Cost function MSE\n",
      "0.262164618130309\n",
      "900 -th iteration.\n",
      "Current parameter Theta\n",
      "[[ 2.06855817]\n",
      " [ 0.83152199]\n",
      " [ 0.11919015]\n",
      " [-0.26896877]\n",
      " [ 0.30847512]\n",
      " [-0.00436818]\n",
      " [-0.03940393]\n",
      " [-0.8949024 ]\n",
      " [-0.8657718 ]]\n",
      "Cost function MSE\n",
      "0.26216212161756575\n",
      "1000 -th iteration.\n",
      "Current parameter Theta\n",
      "[[ 2.06855817]\n",
      " [ 0.8308492 ]\n",
      " [ 0.11901735]\n",
      " [-0.26778493]\n",
      " [ 0.30753457]\n",
      " [-0.00442231]\n",
      " [-0.03937497]\n",
      " [-0.89679388]\n",
      " [-0.86758919]]\n",
      "Cost function MSE\n",
      "0.2621611411581537\n",
      "Current parameter Theta\n",
      "[[ 2.06855817]\n",
      " [ 0.8308492 ]\n",
      " [ 0.11901735]\n",
      " [-0.26778493]\n",
      " [ 0.30753457]\n",
      " [-0.00442231]\n",
      " [-0.03937497]\n",
      " [-0.89679388]\n",
      " [-0.86758919]]\n",
      "Cost function MSE\n",
      "0.2621611411581537\n",
      "Hopefully, you get around 0.2621\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(Theta_initial, X, Y, n_iterations=1000, learning_rate=0.1, n_interval_steps_for_display=100):\n",
    "  if len(Theta_initial.shape) != 2:\n",
    "    raise ValueError('Theta_initial must be 2d-array.')\n",
    "  if Theta_initial.shape[1] != 1:\n",
    "    raise ValueError('The number of columns in Theta_initial must be 1.')\n",
    "  if X.shape[1] != Theta_initial.shape[0]:\n",
    "    raise ValueError('The number of columns in X and the number of rows in Theta_initial must be the same. X.shape =', X.shape, 'Theta_initial.shape =', Theta_initial.shape)\n",
    "  Theta = Theta_initial  \n",
    "  calc_mse(Theta, X, Y)\n",
    "  for i_iteration in range(n_iterations):\n",
    "    Theta = gradient_descent_update(Theta, X, Y, learning_rate)\n",
    "    if (i_iteration + 1) % n_interval_steps_for_display == 0:\n",
    "      print(i_iteration + 1, '-th iteration.')\n",
    "      calc_mse(Theta, X, Y)\n",
    "  final_mse = calc_mse(Theta, X, Y)\n",
    "  return Theta, final_mse\n",
    "\n",
    "Theta_initial = np.zeros([X.shape[1], 1])\n",
    "n_iterations = 1000\n",
    "learning_rate = 0.1\n",
    "Theta, final_mse = gradient_descent(Theta_initial, X, Y, n_iterations=n_iterations, learning_rate=learning_rate)\n",
    "print('Hopefully, you get around', 0.2621)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_Cejo0ieRIQ"
   },
   "outputs": [],
   "source": [
    "# --- Edit the following information ---\n",
    "your_email_address = 'ab0000x@gre.ac.uk'\n",
    "your_student_id = '000000000'\n",
    "your_first_name = 'your_first_name'\n",
    "your_last_name = 'your_last_name'\n",
    "# --- Edit the above information ---\n",
    "\n",
    "# After filling the above information, execute this cell by pressing Shift + Enter\n",
    "\n",
    "# --- Don't touch the below ---\n",
    "# Execute after filling the above descriptions by pressing Shift + Enter\n",
    "!pip install pycryptodome\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, warnings\n",
    "import json\n",
    "from Crypto.PublicKey import RSA\n",
    "from Crypto.Cipher import PKCS1_OAEP\n",
    "\n",
    "submission_id = 'comp-1801_20201009-01'\n",
    "student_information = dict(email=your_email_address, id=your_student_id, first_name=your_first_name, last_name=your_last_name)\n",
    "answer = dict(Theta=Theta.tolist(), final_mse=final_mse.tolist())\n",
    "submission_dict = dict(submission_id=submission_id, student_information=student_information, answer=answer)\n",
    "submission_json = json.dumps(submission_dict)\n",
    "\n",
    "def get_questions(in_url):\n",
    "    res = urllib.request.urlopen(in_url)\n",
    "    soup = BeautifulSoup(res.read(), 'html.parser')\n",
    "    get_names = lambda f: [v for k,v in f.attrs.items() if 'label' in k]\n",
    "    get_name = lambda f: get_names(f)[0] if len(get_names(f))>0 else 'unknown'\n",
    "    all_questions = soup.form.findChildren(attrs={'name': lambda x: x and x.startswith('entry.')})\n",
    "    return {get_name(q): q['name'] for q in all_questions}\n",
    "\n",
    "def submit_response(form_url, cur_questions, verbose=False, **answers):\n",
    "    submit_url = form_url.replace('/viewform', '/formResponse')\n",
    "    form_data = {'draftResponse':[],\n",
    "                'pageHistory':0}\n",
    "    for v in cur_questions.values():\n",
    "        form_data[v] = ''\n",
    "    for k, v in answers.items():\n",
    "        if k in cur_questions:\n",
    "            form_data[cur_questions[k]] = v\n",
    "        else:\n",
    "            warnings.warn('Unknown Question: {}'.format(k), RuntimeWarning)\n",
    "    if verbose:\n",
    "        print(form_data)\n",
    "    user_agent = {'Referer':form_url,\n",
    "                  'User-Agent': \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.52 Safari/537.36\"}\n",
    "    return requests.post(submit_url, data=form_data, headers=user_agent)\n",
    "\n",
    "\n",
    "FORM_URL = \"https://docs.google.com/forms/d/e/1FAIpQLScNs3Cf6DnNCBCUyPGfp22mI3FYVBfTNbGi0TxZ0_SKo9fgCw/viewform\"\n",
    "anno_questions = get_questions(FORM_URL)\n",
    "public_key_utf = '''-----BEGIN PUBLIC KEY-----\n",
    "MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAp/lFj1VO6DQ+Ot27oamm\n",
    "KImRJiXz7IlhdlfkAmytONDQAtvgp9/AqfHyIA0+YnaTDGditMK4t1u6s2YvYlW8\n",
    "5tKbAkbziDAOyaxkepwEw47ldco3hh8p+N42nymWZJp7GKwaHUJ/k1S5sTzFso9o\n",
    "8/szKGlHUq3lpQdQeWScAirCvCewqJFrJWiLymoS0IbeeCzxCJxqmLwx4kXjCTeU\n",
    "c9yUqCi+dZ41Cebd8z5y4Ekf58JP+jh/B0VPHV5cR2D/S3zrhWjPnSU4nCKef5pE\n",
    "b863LlyJ1/sKheanBTq7+9rxMf2rNrsH8Nea4UW2gwtPgOogWFdiWgKYl7B1ks7E\n",
    "OQIDAQAB\n",
    "-----END PUBLIC KEY-----'''\n",
    "\n",
    "split_n = lambda text, n: [ text[i*n:i*n+n] for i in range(len(text)//n) ]\n",
    "def split_n(string, length):\n",
    "    return (string[0+i:length+i] for i in range(0, len(string), length))\n",
    "answer_json_list = split_n(submission_json, 32)\n",
    "cipher_rsa = PKCS1_OAEP.new(RSA.import_key(public_key_utf.encode('utf-8')))\n",
    "encrypted_answer_json = '\\n'.join([cipher_rsa.encrypt(line.encode()).hex() for line in answer_json_list])\n",
    "submit_response(FORM_URL, {'answer': 'entry.1985698402'}, **{'answer': encrypted_answer_json})\n",
    "print('Successfully submitted!!')\n",
    "print('Check your information: ', ', '.join([': '.join([k, str(v)]) for k, v in student_information.items()]), '\\n', 'Your answer: ', ', '.join([': '.join([k, str(v)]) for k, v in answer.items()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lpy9b-W-jGv1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "comp-1801-20201009-01-students.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
